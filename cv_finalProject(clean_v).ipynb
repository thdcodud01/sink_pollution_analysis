{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_35soE4uLIrI"
      },
      "source": [
        "작업 디렉토리 설정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/wkentaro/labelme.git"
      ],
      "metadata": {
        "id": "UuL0eIAQ9UVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_xMYhaQJ66x"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from skimage.feature import local_binary_pattern\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import json\n",
        "import labelme\n",
        "import PIL.Image\n",
        "from labelme import utils\n",
        "\n",
        "# 📁 구글 드라이브 마운트 및 기본 경로 설정\n",
        "drive.mount('/content/drive')\n",
        "base_dir = '/content/drive/MyDrive/SmartSan_Project/OpenImages_YOLO'\n",
        "os.makedirs(base_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4kpxv6XLGrD"
      },
      "source": [
        "필요한 Open Images 파일 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFDA5-o5KhUC"
      },
      "outputs": [],
      "source": [
        "# 클래스 설명 파일\n",
        "!wget https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv -P {base_dir}\n",
        "\n",
        "# validation bounding box\n",
        "!wget https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv -P {base_dir}\n",
        "\n",
        "# validation 이미지 리스트\n",
        "!wget https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv -P {base_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-7WAPlpK9hf"
      },
      "source": [
        "- 필요한 라벨만 필터링해서 저장\n",
        "- 해당 라벨에 포함된 이미지들만 리스트업"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgTzJPWGKTeo"
      },
      "outputs": [],
      "source": [
        "# 🧹 대상 클래스 필터링\n",
        "bbox_csv_path = f\"{base_dir}/validation-annotations-bbox.csv\"\n",
        "bbox_df = pd.read_csv(bbox_csv_path)\n",
        "target_classes = {\"/m/0c_jw\": \"sink\"}\n",
        "filtered_df = bbox_df[bbox_df['LabelName'].isin(target_classes.keys())]\n",
        "filtered_df.to_csv(f\"{base_dir}/filtered_validation_boxes.csv\", index=False)\n",
        "print(f\"✅ 대상 클래스만 추출 완료: {filtered_df.shape[0]}개 bounding box\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBMtLUicK49l"
      },
      "source": [
        "이미지 다운로드 + 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iGozVTvK3yV"
      },
      "outputs": [],
      "source": [
        "# 🧳 이미지 다운로드\n",
        "image_ids = filtered_df['ImageID'].unique()[:500]  # 최대 500장\n",
        "image_dir = os.path.join(base_dir, 'images', 'train')\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "base_img_url = \"https://open-images-dataset.s3.amazonaws.com/validation\"\n",
        "for img_id in tqdm(image_ids):\n",
        "    img_url = f\"{base_img_url}/{img_id}.jpg\"\n",
        "    img_path = os.path.join(image_dir, f\"{img_id}.jpg\")\n",
        "    try:\n",
        "        r = requests.get(img_url, timeout=10)\n",
        "        with open(img_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ {img_id} 다운로드 실패: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP4hlYzWLvAv"
      },
      "source": [
        "YOLO 포맷 라벨 파일 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZUDwrrcLt1g"
      },
      "outputs": [],
      "source": [
        "# 🏷️ YOLO 포맷 라벨 생성\n",
        "label_dir = os.path.join(base_dir, 'labels', 'train')\n",
        "os.makedirs(label_dir, exist_ok=True)\n",
        "class_id_map = {\"/m/0c_jw\": 0}  # sink 클래스 라벨\n",
        "grouped = filtered_df.groupby('ImageID')\n",
        "for img_id, group in grouped:\n",
        "    if img_id not in image_ids:\n",
        "        continue\n",
        "    label_path = os.path.join(label_dir, f\"{img_id}.txt\")\n",
        "    with open(label_path, 'w') as f:\n",
        "        for _, row in group.iterrows():\n",
        "            class_id = class_id_map[row['LabelName']]\n",
        "            x_center = (row['XMin'] + row['XMax']) / 2\n",
        "            y_center = (row['YMin'] + row['YMax']) / 2\n",
        "            width = row['XMax'] - row['XMin']\n",
        "            height = row['YMax'] - row['YMin']\n",
        "            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j2Gf8hDMQlb"
      },
      "source": [
        "data.yaml 생성 (YOLO 학습 설정)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA4cf6evMPzd"
      },
      "outputs": [],
      "source": [
        "# 📄 data.yaml 생성\n",
        "yaml_path = os.path.join(base_dir, \"data.yaml\")\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(f\"\"\"\n",
        "path: {base_dir}\n",
        "train: images/train\n",
        "val: images/train\n",
        "\n",
        "names:\n",
        "  0: sink\n",
        "\"\"\")\n",
        "print(\"✅ data.yaml 생성 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrti1xlfMT5J"
      },
      "source": [
        "YOLOv8 학습 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V730ceZTmdJg"
      },
      "outputs": [],
      "source": [
        "# 🧳 실사 이미지 및 라벨 자동 복사\n",
        "zip_extracted_path = '/content/drive/MyDrive/sink_labels/'  # 라벨링 zip 푼 경로\n",
        "img_train_path = os.path.join(base_dir, 'images/train')\n",
        "label_train_path = os.path.join(base_dir, 'labels/train')\n",
        "\n",
        "for file in os.listdir(zip_extracted_path):\n",
        "    if file.endswith('.jpg'):\n",
        "        shutil.copy(os.path.join(zip_extracted_path, file), img_train_path)\n",
        "    elif file.endswith('.txt'):\n",
        "        shutil.copy(os.path.join(zip_extracted_path, file), label_train_path)\n",
        "\n",
        "print(\"✅ 실사 이미지 및 라벨 정리 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5IHxEr4MVaA"
      },
      "outputs": [],
      "source": [
        "# 🧳 실사 이미지 및 라벨 자동 복사\n",
        "zip_extracted_path = '/content/drive/MyDrive/sink_labels/'  # 라벨링 zip 푼 경로\n",
        "img_train_path = os.path.join(base_dir, 'images/train')\n",
        "label_train_path = os.path.join(base_dir, 'labels/train')\n",
        "\n",
        "for file in os.listdir(zip_extracted_path):\n",
        "    if file.endswith('.jpg'):\n",
        "        shutil.copy(os.path.join(zip_extracted_path, file), img_train_path)\n",
        "    elif file.endswith('.txt'):\n",
        "        shutil.copy(os.path.join(zip_extracted_path, file), label_train_path)\n",
        "print(\"✅ 실사 이미지 및 라벨 정리 완료!\")\n",
        "\n",
        "# 🔁 Fine-tuning 시작\n",
        "model = YOLO('yolov8n.pt')  # 기존 best.pt 대신 경량 YOLO 모델로 시작\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=25,\n",
        "    imgsz=960,\n",
        "    batch=8\n",
        ")\n",
        "print(\"✅ Fine-tuning 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spLthue7blko"
      },
      "source": [
        "탐지 모델 로딩 및 적용(테스트 데이터)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDJb9updFWcr"
      },
      "outputs": [],
      "source": [
        "# crop 및 output 폴더 초기화\n",
        "crop_dir = '/content/drive/MyDrive/SmartSan_Project/cropped_dataset/sink'\n",
        "output_dir = '/content/drive/MyDrive/SmartSan_Project/output'\n",
        "\n",
        "for path in [crop_dir, output_dir]:\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "print(\"✅ crop_dir 및 output_dir 초기화 완료\")\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO('runs/detect/train/weights/best.pt')\n",
        "\n",
        "# 경로 설정\n",
        "sink_labels_dirs = [\n",
        "    '/content/drive/MyDrive/sink_labels',  # 첫 번째 라벨 폴더\n",
        "    '/content/drive/MyDrive/sink_labels/sink_labels2',  # 두 번째 라벨 폴더\n",
        "    '/content/drive/MyDrive/sink_labels/sink_labels3'  # 세 번째 라벨 폴더\n",
        "]\n",
        "raw_images_dir = '/content/drive/MyDrive/SmartSan_Project/raw_images'\n",
        "output_dir = '/content/drive/MyDrive/SmartSan_Project/output'\n",
        "os.makedirs(raw_images_dir, exist_ok=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 이미지 파일 자동 복사 (sink_labels2 라벨 파일에 맞는 이미지 복사)\n",
        "for directory in sink_labels_dirs:\n",
        "    label_files = [f for f in os.listdir(directory) if f.endswith('.txt')]  # .txt 라벨 파일만 읽기\n",
        "\n",
        "    for label_file in label_files:\n",
        "        # 이미지 파일명 생성\n",
        "        img_name = label_file.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(raw_images_dir, img_name)\n",
        "\n",
        "        # 이미지가 이미 존재하는지 확인\n",
        "        if not os.path.exists(img_path):\n",
        "            # 이미지는 raw_images 폴더에 넣기 위해서 복사\n",
        "            src_img_path = os.path.join(directory, img_name)\n",
        "\n",
        "            if os.path.exists(src_img_path):  # 원본 이미지가 있는지 확인\n",
        "                shutil.copy(src_img_path, img_path)  # 이미지를 raw_images 폴더로 복사\n",
        "                print(f\"✅ {img_name} 이미지 복사 완료.\")\n",
        "            else:\n",
        "                print(f\"❌ {img_name} 이미지를 찾을 수 없습니다.\")\n",
        "        else:\n",
        "            print(f\"✅ {img_name} 이미지가 이미 존재합니다.\")\n",
        "\n",
        "# 자동으로 탐지 및 결과 저장\n",
        "image_files = [f for f in os.listdir(raw_images_dir) if f.endswith('.jpg')]\n",
        "\n",
        "# 이미지가 있는지 확인\n",
        "if len(image_files) == 0:\n",
        "    print(\"❌ raw_images 폴더에 이미지 파일이 없습니다.\")\n",
        "else:\n",
        "    print(f\"✅ 총 {len(image_files)}개의 이미지가 존재합니다.\")\n",
        "\n",
        "# YOLO 탐지 수행 및 결과 저장\n",
        "for img_file in image_files:\n",
        "    img_path = os.path.join(raw_images_dir, img_file)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"❌ {img_file} 없음 - 스킵\")\n",
        "        continue\n",
        "\n",
        "    # YOLO 탐지 수행\n",
        "    results = model(img_path)\n",
        "\n",
        "    # 결과 이미지 저장\n",
        "    save_path = os.path.join(output_dir, f\"result_{img_file}\")\n",
        "    results[0].save(filename=save_path)\n",
        "\n",
        "    print(f\"✅ 탐지 완료: {img_file} 저장됨 -> {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAnCiPgKscAq"
      },
      "source": [
        "mAP 학습 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsOTu9fsre_1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# mAP 그래프 시각화\n",
        "result_graph_path = 'runs/detect/train/results.png'\n",
        "display(Image(filename=result_graph_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXh0E9RCs4RP"
      },
      "source": [
        "YOLO 기반 자동 crop 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b60ulwSesgeg"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO('runs/detect/train/weights/best.pt')\n",
        "\n",
        "# 폴더 설정\n",
        "raw_dir = '/content/drive/MyDrive/SmartSan_Project/raw_images'\n",
        "crop_dir = '/content/drive/MyDrive/SmartSan_Project/cropped_dataset/sink'\n",
        "os.makedirs(crop_dir, exist_ok=True)\n",
        "\n",
        "# raw_images 폴더에 있는 모든 .jpg 이미지 파일 읽기\n",
        "image_files = [f for f in os.listdir(raw_dir) if f.endswith('.jpg')]\n",
        "\n",
        "# 이미지가 있는지 확인\n",
        "if len(image_files) == 0:\n",
        "    print(\"❌ raw_images 폴더에 이미지가 없습니다.\")\n",
        "else:\n",
        "    print(f\"✅ 총 {len(image_files)}개의 이미지가 존재합니다.\")\n",
        "\n",
        "# 이미지 반복 탐지 및 크롭\n",
        "for img_file in image_files:\n",
        "    img_path = os.path.join(raw_dir, img_file)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"❌ {img_file} 없음 - 스킵\")\n",
        "        continue\n",
        "\n",
        "    # YOLO 탐지\n",
        "    results = model(img_path)\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # sink class = 0 (sink만 크롭)\n",
        "    for j, box in enumerate(results[0].boxes):\n",
        "        cls_id = int(box.cls[0])\n",
        "        if cls_id == 0:  # sink만 크롭\n",
        "            xyxy = box.xyxy[0].cpu().numpy()\n",
        "            cropped = img.crop(xyxy)\n",
        "\n",
        "            # 이미지를 RGB로 변환하여 저장 (RGBA -> RGB)\n",
        "            cropped = cropped.convert(\"RGB\")\n",
        "\n",
        "            crop_path = os.path.join(crop_dir, f'{img_file[:-4]}_crop{j}.jpg')\n",
        "            cropped.save(crop_path)\n",
        "            print(f\"✅ 저장됨: {crop_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-Net 모델 정의"
      ],
      "metadata": {
        "id": "VNgl0wDLpVN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.enc1 = conv_block(in_channels, 64)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "        self.enc4 = conv_block(256, 512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.bottleneck = conv_block(512, 1024)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = conv_block(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = conv_block(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool(enc1))\n",
        "        enc3 = self.enc3(self.pool(enc2))\n",
        "        enc4 = self.enc4(self.pool(enc3))\n",
        "        bottleneck = self.bottleneck(self.pool(enc4))\n",
        "\n",
        "        dec4 = self.dec4(torch.cat((self.upconv4(bottleneck), enc4), dim=1))\n",
        "        dec3 = self.dec3(torch.cat((self.upconv3(dec4), enc3), dim=1))\n",
        "        dec2 = self.dec2(torch.cat((self.upconv2(dec3), enc2), dim=1))\n",
        "        dec1 = self.dec1(torch.cat((self.upconv1(dec2), enc1), dim=1))\n",
        "\n",
        "        return torch.sigmoid(self.out(dec1))"
      ],
      "metadata": {
        "id": "pQTma2vHpLfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dice Loss + BCEDiceLoss"
      ],
      "metadata": {
        "id": "cxIyq7K95OoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DiceLoss에서는 sigmoid 제거 (입력에 이미 sigmoid 되어 있으니까)\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_score = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
        "        return 1 - dice_score\n",
        "\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self, dice_weight=1.5):\n",
        "        super(BCEDiceLoss, self).__init__()\n",
        "        self.bce = nn.BCELoss()\n",
        "        self.dice = DiceLoss()\n",
        "        self.dice_weight = dice_weight\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        bce_loss = self.bce(inputs, targets)\n",
        "        dice_loss = self.dice(inputs, targets)\n",
        "        return bce_loss + self.dice_weight * dice_loss"
      ],
      "metadata": {
        "id": "L5CkYdsc5QHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "json → mask 변환 시작"
      ],
      "metadata": {
        "id": "aGxN-yvKzH9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install albumentations"
      ],
      "metadata": {
        "id": "-uoP5eBRf8Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "\n",
        "class JointTransform:\n",
        "    def __call__(self, image, mask):\n",
        "        if random.random() > 0.5:\n",
        "            image = TF.hflip(image)\n",
        "            mask = TF.hflip(mask)\n",
        "        if random.random() > 0.5:\n",
        "            angle = random.uniform(-15, 15)\n",
        "            image = TF.rotate(image, angle)\n",
        "            mask = TF.rotate(mask, angle)\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "resize = transforms.Resize((256, 256))\n",
        "\n",
        "class SinkSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None, augment=False):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "        self.joint_transform = JointTransform()\n",
        "        self.image_filenames = sorted([f for f in os.listdir(image_dir) if f.endswith(('jpg', 'png', 'jpeg'))])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_filenames[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "\n",
        "        # 마스크 파일 이름 생성 (중복 방지)\n",
        "        mask_filename = os.path.splitext(img_name)[0] + '_mask.png'\n",
        "        mask_path = os.path.join(self.mask_dir, mask_filename)\n",
        "\n",
        "        # 이미지/마스크 불러오기\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "\n",
        "        # 증강 적용 (학습용에만)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask'].unsqueeze(0).float() / 255.0 # 1채널로 만들고 float 변환\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image)\n",
        "            mask = transforms.ToTensor()(mask)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "mk3h8DkHy1f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋 로딩"
      ],
      "metadata": {
        "id": "T9doZosWGlXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 학습 데이터 준비\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Albumentations transform 정의\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=15, p=0.5),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, p=0.5),\n",
        "    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.3),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# 경로 설정\n",
        "image_dir = \"/content/drive/MyDrive/SmartSan_Project/segmentation_labelme/images\"\n",
        "mask_dir = \"/content/drive/MyDrive/SmartSan_Project/segmentation_labelme/masks\"\n",
        "\n",
        "# 인덱스 분할\n",
        "all_indices = list(range(len(os.listdir(image_dir))))\n",
        "train_indices, val_indices = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dataset 정의 및 Subset 나누기\n",
        "train_dataset_full = SinkSegmentationDataset(image_dir, mask_dir, transform=train_transform)\n",
        "val_dataset_full = SinkSegmentationDataset(image_dir, mask_dir, transform=val_transform)\n",
        "\n",
        "train_dataset = Subset(train_dataset_full, train_indices)\n",
        "val_dataset = Subset(val_dataset_full, val_indices)\n",
        "\n",
        "# DataLoader 설정\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 학습 설정\n",
        "import torch.optim as optim\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet().to(device)\n",
        "criterion = BCEDiceLoss(dice_weight=1.5)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# 디버깅\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# 학습 루프\n",
        "from tqdm import tqdm\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device).squeeze(1)\n",
        "        outputs = model(images).squeeze(1)\n",
        "        loss = criterion(outputs, masks)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    print(f\"✅ Epoch {epoch+1} - 평균 학습 손실: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "hitYP6SdHdvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "캐시 및 불필요한 객체 정리"
      ],
      "metadata": {
        "id": "TiUMrzrd2FyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_DZ1uL8j2DNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 시각화 코드"
      ],
      "metadata": {
        "id": "V5JaXM7S2J3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 모드로 설정\n",
        "model.eval()\n",
        "\n",
        "# 파일 경로\n",
        "img_path = '/content/drive/MyDrive/SmartSan_Project/segmentation_labelme/images/test41.jpg'\n",
        "mask_path = '/content/drive/MyDrive/SmartSan_Project/segmentation_labelme/masks/test41_mask.png'\n",
        "\n",
        "# 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 이미지 불러오기\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "# 마스크 불러오기\n",
        "mask = Image.open(mask_path).convert(\"L\").resize((256, 256))\n",
        "mask_tensor = transforms.ToTensor()(mask).squeeze().numpy()\n",
        "\n",
        "# 추론\n",
        "with torch.no_grad():\n",
        "    pred = model(input_tensor)\n",
        "    pred_mask = (pred.squeeze().cpu().numpy() > 0.5).astype(int)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Input Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(mask_tensor, cmap=\"gray\")\n",
        "plt.title(\"Ground Truth\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(pred_mask, cmap=\"gray\")\n",
        "plt.title(\"Predicted Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EAL67M-G2Dq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 예측 시각화 + 저장"
      ],
      "metadata": {
        "id": "B1xaWIPJgiM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_with_status(model, dataset, index, device, save_dir, show=True):\n",
        "    model.eval()\n",
        "    image, mask = dataset[index]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_input = image.unsqueeze(0).to(device)\n",
        "        output = model(image_input).squeeze().cpu()\n",
        "\n",
        "    pred_mask = (output > 0.1).float()\n",
        "    contamination = pred_mask.sum().item() / pred_mask.numel() * 100\n",
        "\n",
        "    # 🎯 3단계 오염도 기준 (0~15 clean, 15~30 moderate, 30~ dirty)\n",
        "    if contamination < 15:\n",
        "        status = \"Clean\"\n",
        "        box_color = 'blue'\n",
        "    elif contamination < 30:\n",
        "        status = \"Moderate\"\n",
        "        box_color = 'orange'\n",
        "    else:\n",
        "        status = \"Dirty\"\n",
        "        box_color = 'red'\n",
        "\n",
        "    # 시각화\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "    axs[0].imshow(image.permute(1, 2, 0).numpy())\n",
        "    axs[0].set_title(f\"Input Image\\n[{status}] {contamination:.2f}%\")\n",
        "    axs[0].add_patch(plt.Rectangle(\n",
        "        (0, 0), image.shape[2], image.shape[1],\n",
        "        linewidth=4, edgecolor=box_color, facecolor='none'\n",
        "    ))\n",
        "\n",
        "    axs[1].imshow(mask.squeeze().numpy(), cmap='gray')\n",
        "    axs[1].set_title(\"Ground Truth\")\n",
        "\n",
        "    axs[2].imshow(pred_mask.squeeze().numpy(), cmap='gray')\n",
        "    axs[2].set_title(\"Predicted Mask\")\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, f\"result_{index}.png\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/SmartSan_Project/results\"\n",
        "full_dataset = SinkSegmentationDataset(image_dir, mask_dir, transform=val_transform)\n",
        "\n",
        "print(f\"📊 전체 데이터셋 이미지 수: {len(full_dataset)}\")\n",
        "\n",
        "# 전체 이미지 시각화 + 저장\n",
        "for i in range(len(full_dataset)):\n",
        "    print(f\"🔄 이미지 {i} 처리 중...\")\n",
        "    visualize_with_status(model, full_dataset, index=i, device=device, save_dir=save_dir, show=True)"
      ],
      "metadata": {
        "id": "9Kuofxo2gjxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix + Classification Report"
      ],
      "metadata": {
        "id": "WSToDYMwuLfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for i in range(len(full_dataset)):\n",
        "    image, mask = full_dataset[i]\n",
        "    image_input = image.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image_input).squeeze().cpu()\n",
        "\n",
        "    # 예측 오염도 (%)\n",
        "    pred_mask = (output > 0.1).float()\n",
        "    contamination = 100.0 * pred_mask.sum().item() / pred_mask.numel()\n",
        "\n",
        "    # 예측 클래스\n",
        "    if contamination <= 15:\n",
        "        pred = 0  # Clean\n",
        "    elif contamination <= 30:\n",
        "        pred = 1  # Moderate\n",
        "    else:\n",
        "        pred = 2  # Dirty\n",
        "    pred_labels.append(pred)\n",
        "\n",
        "    # 실제 오염도 (%)\n",
        "    true_contam = 100.0 * mask.sum().item() / mask.numel()\n",
        "    if true_contam <= 15:\n",
        "        true = 0\n",
        "    elif true_contam <= 30:\n",
        "        true = 1\n",
        "    else:\n",
        "        true = 2\n",
        "    true_labels.append(true)\n",
        "\n",
        "# 🔢 Confusion Matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Clean\", \"Moderate\", \"Dirty\"])\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"📉 Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 📄 Classification Report\n",
        "report = classification_report(true_labels, pred_labels, target_names=[\"Clean\", \"Moderate\", \"Dirty\"])\n",
        "print(\"📋 Classification Report:\\n\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "Uw_jeKZ6uMMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!zip -r /content/drive/MyDrive/SmartSan_Project.zip /content/drive/MyDrive/SmartSan_Project"
      ],
      "metadata": {
        "id": "uRmCALnYVzE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkJujQ9yVzrZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}